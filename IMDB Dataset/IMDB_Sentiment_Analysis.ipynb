{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b77b3bc",
   "metadata": {},
   "source": [
    "### Sentiment Analysis on IMDB reviw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7699accf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kpoli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer # We also have snowbaallstemmer\n",
    "nltk.download('stopwords')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a9041b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('IMDBDataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d482c270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c86d62",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d255bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = SnowballStemmer('english')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "html_tags_re = re.compile('<.*?>')\n",
    "\n",
    "corpus = [\n",
    "    \" \".join([ps.stem(word) for word in re.sub('[^a-zA-z]',\" \", re.sub(html_tags_re, '', document)).lower().split() \n",
    "              if word not in stop_words])\n",
    "    for document in df['review']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9d1cc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one review mention watch oz episod hook right exact happen first thing struck oz brutal unflinch scene violenc set right word go trust show faint heart timid show pull punch regard drug sex violenc hardcor classic use word call oz nicknam given oswald maximum secur state penitentari focus main emerald citi experiment section prison cell glass front face inward privaci high agenda em citi home mani aryan muslim gangsta latino christian italian irish scuffl death stare dodgi deal shadi agreement never far away would say main appeal show due fact goe show dare forget pretti pictur paint mainstream audienc forget charm forget romanc oz mess around first episod ever saw struck nasti surreal say readi watch develop tast oz got accustom high level graphic violenc violenc injustic crook guard sold nickel inmat kill order get away well manner middl class inmat turn prison bitch due lack street skill prison experi watch oz may becom comfort uncomfort view that get touch darker side'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddb7b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b797e777",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review']\n",
    "\n",
    "y = pd.get_dummies(df['sentiment'])\n",
    "y = y.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63e0eaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a8248f",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb9542a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = CountVectorizer(max_features= 2500,binary = True,ngram_range=(1,2))\n",
    "X_train_cf = cf.fit_transform(X_train).toarray()\n",
    "X_test_cf = cf.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5e757db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8478787878787879"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_cf,y_train)\n",
    "y_pred = mnb.predict(X_test_cf)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee49ab34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7136363636363636"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train_cf,y_train)\n",
    "y_pred_dt = tree.predict(X_test_cf)\n",
    "accuracy_score(y_test,y_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88b53394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5837, 2371],\n",
       "       [2354, 5938]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1507695",
   "metadata": {},
   "source": [
    "### Tf-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34936e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer(max_features=2500,ngram_range=(1,2))\n",
    "X_train_tf = tf.fit_transform(X_train).toarray()\n",
    "X_test_tf = tf.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ff0376c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8483030303030303"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_tf = MultinomialNB()\n",
    "mnb_tf.fit(X_train_tf,y_train)\n",
    "y_pred_tf = mnb_tf.predict(X_test_tf)\n",
    "accuracy_score(y_test,y_pred_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c89cb39",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31c39e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting each of the sentence into words to feed them to the word2vec model\n",
    "words = [sent.split() for sent in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6690b7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'review',\n",
       " 'mention',\n",
       " 'watch',\n",
       " 'oz',\n",
       " 'episod',\n",
       " 'hook',\n",
       " 'right',\n",
       " 'exact',\n",
       " 'happen',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'struck',\n",
       " 'oz',\n",
       " 'brutal',\n",
       " 'unflinch',\n",
       " 'scene',\n",
       " 'violenc',\n",
       " 'set',\n",
       " 'right',\n",
       " 'word',\n",
       " 'go',\n",
       " 'trust',\n",
       " 'show',\n",
       " 'faint',\n",
       " 'heart',\n",
       " 'timid',\n",
       " 'show',\n",
       " 'pull',\n",
       " 'punch',\n",
       " 'regard',\n",
       " 'drug',\n",
       " 'sex',\n",
       " 'violenc',\n",
       " 'hardcor',\n",
       " 'classic',\n",
       " 'use',\n",
       " 'word',\n",
       " 'call',\n",
       " 'oz',\n",
       " 'nicknam',\n",
       " 'given',\n",
       " 'oswald',\n",
       " 'maximum',\n",
       " 'secur',\n",
       " 'state',\n",
       " 'penitentari',\n",
       " 'focus',\n",
       " 'main',\n",
       " 'emerald',\n",
       " 'citi',\n",
       " 'experiment',\n",
       " 'section',\n",
       " 'prison',\n",
       " 'cell',\n",
       " 'glass',\n",
       " 'front',\n",
       " 'face',\n",
       " 'inward',\n",
       " 'privaci',\n",
       " 'high',\n",
       " 'agenda',\n",
       " 'em',\n",
       " 'citi',\n",
       " 'home',\n",
       " 'mani',\n",
       " 'aryan',\n",
       " 'muslim',\n",
       " 'gangsta',\n",
       " 'latino',\n",
       " 'christian',\n",
       " 'italian',\n",
       " 'irish',\n",
       " 'scuffl',\n",
       " 'death',\n",
       " 'stare',\n",
       " 'dodgi',\n",
       " 'deal',\n",
       " 'shadi',\n",
       " 'agreement',\n",
       " 'never',\n",
       " 'far',\n",
       " 'away',\n",
       " 'would',\n",
       " 'say',\n",
       " 'main',\n",
       " 'appeal',\n",
       " 'show',\n",
       " 'due',\n",
       " 'fact',\n",
       " 'goe',\n",
       " 'show',\n",
       " 'dare',\n",
       " 'forget',\n",
       " 'pretti',\n",
       " 'pictur',\n",
       " 'paint',\n",
       " 'mainstream',\n",
       " 'audienc',\n",
       " 'forget',\n",
       " 'charm',\n",
       " 'forget',\n",
       " 'romanc',\n",
       " 'oz',\n",
       " 'mess',\n",
       " 'around',\n",
       " 'first',\n",
       " 'episod',\n",
       " 'ever',\n",
       " 'saw',\n",
       " 'struck',\n",
       " 'nasti',\n",
       " 'surreal',\n",
       " 'say',\n",
       " 'readi',\n",
       " 'watch',\n",
       " 'develop',\n",
       " 'tast',\n",
       " 'oz',\n",
       " 'got',\n",
       " 'accustom',\n",
       " 'high',\n",
       " 'level',\n",
       " 'graphic',\n",
       " 'violenc',\n",
       " 'violenc',\n",
       " 'injustic',\n",
       " 'crook',\n",
       " 'guard',\n",
       " 'sold',\n",
       " 'nickel',\n",
       " 'inmat',\n",
       " 'kill',\n",
       " 'order',\n",
       " 'get',\n",
       " 'away',\n",
       " 'well',\n",
       " 'manner',\n",
       " 'middl',\n",
       " 'class',\n",
       " 'inmat',\n",
       " 'turn',\n",
       " 'prison',\n",
       " 'bitch',\n",
       " 'due',\n",
       " 'lack',\n",
       " 'street',\n",
       " 'skill',\n",
       " 'prison',\n",
       " 'experi',\n",
       " 'watch',\n",
       " 'oz',\n",
       " 'may',\n",
       " 'becom',\n",
       " 'comfort',\n",
       " 'uncomfort',\n",
       " 'view',\n",
       " 'that',\n",
       " 'get',\n",
       " 'touch',\n",
       " 'darker',\n",
       " 'side']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e7ace69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the word2vec pretrained model\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model_path = api.load(\"word2vec-google-news-300\", return_path=True)\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0db80cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tome', 0.7485830783843994),\n",
       " ('books', 0.7379177808761597),\n",
       " ('memoir', 0.7302926778793335),\n",
       " ('paperback_edition', 0.6868364214897156),\n",
       " ('autobiography', 0.6741527318954468),\n",
       " ('memoirs', 0.6505153179168701),\n",
       " ('Book', 0.6479282975196838),\n",
       " ('paperback', 0.6471226811408997),\n",
       " ('novels', 0.6341459155082703),\n",
       " ('hardback', 0.6283079981803894)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('book')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b79aac",
   "metadata": {},
   "source": [
    "### Avg Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2c67e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def avg_word2vec(doc):\n",
    "    # Remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in model]\n",
    "    return np.mean(model[doc], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f246e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 50000/50000 [00:10<00:00, 4774.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "X = []\n",
    "for i in tqdm(range(len(words))):\n",
    "    X.append(avg_word2vec(words[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b211e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model Building for this\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21f97490",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wv = np.array(X_train)\n",
    "X_test_wv = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "84502504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33500, 300)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_wv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9231715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16500, 300)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_wv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1830860e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train_wv,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26fa6611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6417575757575757"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_wv = dt.predict(X_test_wv)\n",
    "\n",
    "accuracy_score(y_test,y_pred_wv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
